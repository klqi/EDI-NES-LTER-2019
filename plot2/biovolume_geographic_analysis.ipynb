{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt user for manual or automated argument\n",
    "while (True):\n",
    "    dataset_type = str(input(\"Please enter 'manual' or 'automated' for the type of data set you are processing: \"))\n",
    "    # make case insenstive\n",
    "    dataset_type = dataset_type.lower()\n",
    "    if (dataset_type == \"manual\" or dataset_type == \"automated\"):\n",
    "        break\n",
    "    print(\"Invalid argument\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first call bash script to get necessary file inputs\n",
    "# for geographic script, choose query_samples for underway gps data alignment as input script\n",
    "# for worms script, choose names_ids.csv for input script\n",
    "# subprocess.call(['./exec.sh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read different columns based on dataset type\n",
    "if (dataset_type == 'manual'):\n",
    "    columns = ['permalink', 'namespace_manual', 'worms_higher_order_manual', 'Biovolume', 'MajorAxisLength']\n",
    "else:\n",
    "    columns = ['permalink', 'namespace_automated', 'Biovolume', 'MajorAxisLength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in level 1_b file\n",
    "all_rois = pd.read_csv('level_1b.csv', usecols=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Prompt user for type of analsyis\n",
    "while (True):\n",
    "    analysis_type = str(input(\"Please enter 'species', 'higher ranks', or 'all' for the type analysis: \"))\n",
    "    # make case insenstive\n",
    "    analsyis_type = analysis_type.lower()\n",
    "    if (analysis_type == 'species' or analysis_type == 'higher ranks' or analysis_type == 'all'):\n",
    "        break\n",
    "    print(\"Invalid argument\")\n",
    "# Show drop down list if 'species' is chosen\n",
    "if (analysis_type == 'species'):\n",
    "    higher_rank = 'worms_higher_order_{}'.format(dataset_type)\n",
    "    all_species = set(all_rois.loc[all_rois[higher_rank].notna(), \n",
    "                                  'namespace_{}'.format(dataset_type)])\n",
    "    print(all_species)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt user to ask for desired size distribution, keep at 20 for now\n",
    "threshold = input('Please enter minimum Major Axis Length to analyze (micrometers): ')\n",
    "threshold = float(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get higher order data if dataset is automated\n",
    "if (dataset_type == 'automated'):\n",
    "    auto_taxon_info = pd.read_csv('resolved_auto.csv', \n",
    "                                  usecols=['name', 'resolved_names', 'resolved_higher_order_fromgnr'])\n",
    "    # merge to get taxa data\n",
    "    all_rois = pd.merge(all_rois, auto_taxon_info, how='left', left_on='namespace_automated', right_on='name')\n",
    "    # rename resolved_higher_order column to match\n",
    "    all_rois.rename(columns={'resolved_higher_order_fromgnr':'worms_higher_order_automated'}, inplace=True)\n",
    "else:\n",
    "    man_taxon_info = pd.read_csv('resolved_manual.csv', \n",
    "                                  usecols=['name', 'resolved_names'])\n",
    "    # merge to get taxa data\n",
    "    samples = pd.merge(all_rois, man_taxon_info, how='left', left_on='namespace_manual', right_on='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate out roi id from permalink\n",
    "all_rois['roi'] = all_rois['permalink']\n",
    "all_rois.roi = all_rois.roi.str.slice(68, 74)\n",
    "# gets rid of leading zeros\n",
    "all_rois.roi = all_rois.roi.str.lstrip(\"0\")\n",
    "# cut permalink to just be permalink of sample\n",
    "all_rois.permalink = all_rois.permalink.str.slice(0, 67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in gps coordinates file\n",
    "coords = pd.read_csv('comparison.csv', usecols=['pid', 'gps_furuno_latitude'])\n",
    "# merge with all_rois based on smaple ids\n",
    "all_rois = pd.merge(all_rois, coords, how='left', left_on='permalink', right_on='pid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total biovolume per sample\n",
    "total = all_rois.groupby('permalink')['Biovolume'].sum().reset_index()\n",
    "total.rename(columns={'Biovolume':'total_biovolume'}, inplace=True)\n",
    "# merge 2 data frames based on sample_identifier\n",
    "all_rois = pd.merge(all_rois, total, how='left', on='permalink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out rows below threshold\n",
    "all_rois = all_rois[all_rois.MajorAxisLength > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by sample identifiers and higher ranks to calculate total biovolume per ranking\n",
    "rois = all_rois.groupby(\n",
    "    ['permalink', 'worms_higher_order_{}'.format(dataset_type)]).agg(\n",
    "    {\n",
    "        'Biovolume': 'sum',\n",
    "        'gps_furuno_latitude': 'first',\n",
    "        'total_biovolume': 'first'\n",
    "    }\n",
    ").reset_index()\n",
    "# calculate percent biovolume\n",
    "rois['percent_biovolume'] = rois['Biovolume']/rois['total_biovolume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take duplicate latitudes and add their concentrations together\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "# use unstack()\n",
    "rois = rois.groupby(['gps_furuno_latitude','worms_higher_order_{}'.format(dataset_type)]).sum()['percent_biovolume']\n",
    "rois.unstack().plot(ax=ax)\n",
    "# add titles and axes labels\n",
    "plt.xlabel('LTER Stations')\n",
    "plt.ylabel('% Biovolume in targets with Major Axis Length > {} micrometers'.format(threshold))\n",
    "plt.title('MVCO Phytoplankton Biovolume ({} classifications)'.format(dataset_type))\n",
    "plt.grid(True)\n",
    "# set stations as tick marks\n",
    "ax.set_xticks([41.1967, 41.03, 40.8633, 40.6967, 40.5133, 40.3633, 40.2267, 40.1367, 40.0983, 39.94, 39.7733])\n",
    "ax.set_xticklabels(np.arange(1,12))\n",
    "# set comments\n",
    "ax.text(41.1967, -0.15, \"Coast\", size = 15, ha = 'center')\n",
    "ax.text(39.7733, -0.15, \"Offshore\", size = 15, ha = 'center')\n",
    "# invert x axis\n",
    "ax.invert_xaxis()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
